{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3056ef21",
   "metadata": {},
   "source": [
    "# Tłumaczenie Transformerem\n",
    "\n",
    "![Alt text](translation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e491dc58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-11T21:15:41.750311Z",
     "iopub.status.busy": "2023-03-11T21:15:41.749655Z",
     "iopub.status.idle": "2023-03-11T21:15:48.333591Z",
     "shell.execute_reply": "2023-03-11T21:15:48.332497Z"
    },
    "papermill": {
     "duration": 6.595399,
     "end_time": "2023-03-11T21:15:48.336261",
     "exception": false,
     "start_time": "2023-03-11T21:15:41.740862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import string\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fcd4a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 100_000\n",
    "sequence_length = 30"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68f9ec5f",
   "metadata": {
    "papermill": {
     "duration": 0.007735,
     "end_time": "2023-03-11T21:15:48.557506",
     "exception": false,
     "start_time": "2023-03-11T21:15:48.549771",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Przygotowanie danych\n",
    "![Alt text](preprocessing.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "623e2ed2",
   "metadata": {},
   "source": [
    "## Wczytanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85ddef18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-11T21:15:48.590891Z",
     "iopub.status.busy": "2023-03-11T21:15:48.589444Z",
     "iopub.status.idle": "2023-03-11T21:15:49.100476Z",
     "shell.execute_reply": "2023-03-11T21:15:49.099058Z"
    },
    "papermill": {
     "duration": 0.522132,
     "end_time": "2023-03-11T21:15:49.102834",
     "exception": false,
     "start_time": "2023-03-11T21:15:48.580702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6332021</th>\n",
       "      <td>• Imigracyjne profile przesiewowe Podręcznik</td>\n",
       "      <td>[start] • Immigration Screening Profiles Manua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7267993</th>\n",
       "      <td>Depozyty wycenia się według ich wartości nomin...</td>\n",
       "      <td>[start] Debts are valued at their face value c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5812057</th>\n",
       "      <td>Naprawdę wierzę, że to, co dziś widzimy, jest ...</td>\n",
       "      <td>[start] I really do believe that what we are s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798116</th>\n",
       "      <td>Zwrot kosztów [C.E.A., ss.</td>\n",
       "      <td>[start] Reimbursement [C.E.A., ss. [end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4703218</th>\n",
       "      <td>Przemysł dziewiarski twierdził, że wraz z klie...</td>\n",
       "      <td>[start] The knitting industry submitted that i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    source  \\\n",
       "6332021       • Imigracyjne profile przesiewowe Podręcznik   \n",
       "7267993  Depozyty wycenia się według ich wartości nomin...   \n",
       "5812057  Naprawdę wierzę, że to, co dziś widzimy, jest ...   \n",
       "1798116                         Zwrot kosztów [C.E.A., ss.   \n",
       "4703218  Przemysł dziewiarski twierdził, że wraz z klie...   \n",
       "\n",
       "                                                    target  \n",
       "6332021  [start] • Immigration Screening Profiles Manua...  \n",
       "7267993  [start] Debts are valued at their face value c...  \n",
       "5812057  [start] I really do believe that what we are s...  \n",
       "1798116           [start] Reimbursement [C.E.A., ss. [end]  \n",
       "4703218  [start] The knitting industry submitted that i...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '../data/en-pl.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df['source'] = df['pl']\n",
    "df['target'] = df['en'].apply(lambda x: '[start] ' + x + ' [end]')\n",
    "df = df.drop(['pl', 'en'], axis=1)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c88924f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba pryzkładów:  7964839\n"
     ]
    }
   ],
   "source": [
    "print('Liczba pryzkładów: ', len(df))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9c359e5",
   "metadata": {},
   "source": [
    "## Podział na podzbiory\n",
    "<div><img src=\"split.png\" width=\"800\"/></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b31d06e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-11T21:15:49.139118Z",
     "iopub.status.busy": "2023-03-11T21:15:49.137517Z",
     "iopub.status.idle": "2023-03-11T21:15:49.324222Z",
     "shell.execute_reply": "2023-03-11T21:15:49.320248Z"
    },
    "papermill": {
     "duration": 0.199592,
     "end_time": "2023-03-11T21:15:49.327853",
     "exception": false,
     "start_time": "2023-03-11T21:15:49.128261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "\n",
    "train_size = int(len(df) * 0.9)\n",
    "val_size = int(len(df) * 0.05)\n",
    "test_size = int(len(df) * 0.05)\n",
    "\n",
    "train_df = df[:train_size]\n",
    "val_df = df[train_size:train_size+val_size]\n",
    "test_df = df[train_size+val_size:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea84b2ce",
   "metadata": {},
   "source": [
    "## Zamiana słów na liczby\n",
    "<div><img src=\"vectorization.png\" width=\"300\"/></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a3a2e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_chars = string.punctuation\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    " \n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(\n",
    "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa29ac95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-11T21:15:49.417259Z",
     "iopub.status.busy": "2023-03-11T21:15:49.416961Z",
     "iopub.status.idle": "2023-03-11T21:16:10.211774Z",
     "shell.execute_reply": "2023-03-11T21:16:10.210723Z"
    },
    "papermill": {
     "duration": 20.806875,
     "end_time": "2023-03-11T21:16:10.214442",
     "exception": false,
     "start_time": "2023-03-11T21:15:49.407567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_vectorization = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "target_vectorization = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length + 1, # add +1 token to our target sentences since they'll be shifted right by 1 during training\n",
    "    standardize=custom_standardization,\n",
    ")\n",
    "\n",
    "source_vectorization.adapt(train_df['source'].values)\n",
    "target_vectorization.adapt(train_df['target'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "816d336c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_text_vectorization(text_vec, path):\n",
    "    standardize = target_vectorization._standardize\n",
    "    target_vectorization._standardize = None\n",
    "    pickle.dump({\n",
    "        'config': text_vec.get_config(),\n",
    "        'weights': text_vec.get_weights()\n",
    "        }, open(path, \"wb\")\n",
    "    )\n",
    "    target_vectorization._standardize = standardize\n",
    "    \n",
    "save_text_vectorization(source_vectorization, '../checkpoints/source_vec.pkl')\n",
    "save_text_vectorization(target_vectorization, '../checkpoints/target_vec.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff57e902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_vectorization(path, standardize=None):\n",
    "    from_disk = pickle.load(open(path, \"rb\"))\n",
    "    new_v = tf.keras.layers.TextVectorization.from_config(from_disk['config'])\n",
    "    if standardize:\n",
    "        new_v._standardize = standardize\n",
    "    new_v.adapt(tf.data.Dataset.from_tensor_slices([\"xyz\"]))\n",
    "    new_v.set_weights(from_disk['weights'])\n",
    "    return new_v\n",
    "\n",
    "source_vectorization = load_text_vectorization('../checkpoints/source_vec.pkl')\n",
    "target_vectorization = load_text_vectorization('../checkpoints/target_vec.pkl', custom_standardization)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6da61018",
   "metadata": {},
   "source": [
    "## Embeddingi\n",
    "<div><img src=\"embedding.png\" width=\"500\"/></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2489cab4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-11T21:16:14.226341Z",
     "iopub.status.busy": "2023-03-11T21:16:14.225469Z",
     "iopub.status.idle": "2023-03-11T21:16:14.235651Z",
     "shell.execute_reply": "2023-03-11T21:16:14.234365Z"
    },
    "papermill": {
     "duration": 0.024289,
     "end_time": "2023-03-11T21:16:14.237957",
     "exception": false,
     "start_time": "2023-03-11T21:16:14.213668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = tf.keras.layers.Embedding(input_dim=input_dim, output_dim=output_dim) # token embedding layer\n",
    "        self.position_embeddings = tf.keras.layers.Embedding(input_dim=sequence_length, output_dim=output_dim) # position embedding layer\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        embedded_tokens = self.token_embeddings(inputs) # embed the tokens\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1) # create the positional information\n",
    "        embedded_positions = self.position_embeddings(positions) # embed the positions \n",
    "        return embedded_tokens + embedded_positions # add the token and position embeddings to create the positional embeddings\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(PositionalEmbedding, self).get_config()\n",
    "        config.update({\n",
    "            \"input_dim\": self.input_dim,\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "afb5954e",
   "metadata": {},
   "source": [
    "## Attention\n",
    "<div><img src=\"attention2.png\" width=\"400\"/></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6603854e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-11T21:16:14.540900Z",
     "iopub.status.busy": "2023-03-11T21:16:14.540100Z",
     "iopub.status.idle": "2023-03-11T21:16:14.548405Z",
     "shell.execute_reply": "2023-03-11T21:16:14.547426Z"
    },
    "papermill": {
     "duration": 0.020436,
     "end_time": "2023-03-11T21:16:14.550520",
     "exception": false,
     "start_time": "2023-03-11T21:16:14.530084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, use_causal_mask=False):\n",
    "    d_k = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scores = tf.matmul(q, k, transpose_b=True) # Matmul of Q and K\n",
    "    scaled_scores = scores / tf.math.sqrt(d_k) # Scale\n",
    "    if use_causal_mask:\n",
    "        scaled_scores = mask_attn_weights(scaled_scores) # Mask (opt.)\n",
    "    weights = tf.nn.softmax(scaled_scores, axis=-1) # SoftMax\n",
    "    output = tf.matmul(weights, v) # Matmul of SoftMax and V\n",
    "    return output\n",
    "\n",
    "def shape_list(x):\n",
    "    static = x.shape.as_list()\n",
    "    dynamic = tf.shape(x)\n",
    "    return [dynamic[i] if s is None else s for i, s in enumerate(static)]\n",
    "\n",
    "def attention_mask(nd, ns, *, dtype):\n",
    "    i = tf.range(nd)[:,None]\n",
    "    j = tf.range(ns)\n",
    "    m = i >= j - ns + nd\n",
    "    return tf.cast(m, dtype)\n",
    "\n",
    "def mask_attn_weights(w):\n",
    "    _, _, nd, ns = shape_list(w)\n",
    "    b = attention_mask(nd, ns, dtype=w.dtype)\n",
    "    b = tf.reshape(b, [1, 1, nd, ns])\n",
    "    w = w*b - tf.cast(1e10, w.dtype)*(1-b)\n",
    "    return w"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b7aba0f3",
   "metadata": {},
   "source": [
    "## Multi Head Attention\n",
    "<div><img src=\"multi_attention_1.jpg\" width=\"400\"/></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bb3ca80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-11T21:16:16.368012Z",
     "iopub.status.busy": "2023-03-11T21:16:16.367718Z",
     "iopub.status.idle": "2023-03-11T21:16:16.379572Z",
     "shell.execute_reply": "2023-03-11T21:16:16.378577Z"
    },
    "papermill": {
     "duration": 0.024366,
     "end_time": "2023-03-11T21:16:16.381708",
     "exception": false,
     "start_time": "2023-03-11T21:16:16.357342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, h, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.h = h\n",
    "        if embed_dim % h != 0:\n",
    "            raise ValueError(\n",
    "                f\"dimension of the embedding space = {embed_dim} should be divisible by number of heads = {h}\"\n",
    "            )\n",
    "        self.q_linear = tf.keras.layers.Dense(embed_dim)\n",
    "        self.k_linear = tf.keras.layers.Dense(embed_dim)\n",
    "        self.v_linear = tf.keras.layers.Dense(embed_dim)\n",
    "        self.concat_linear = tf.keras.layers.Dense(embed_dim)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, shape=(batch_size, -1, self.h, self.embed_dim // self.h))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def concat_heads(self, x, batch_size):\n",
    "        x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        return tf.reshape(x, (batch_size, -1, self.embed_dim))\n",
    "\n",
    "    def call(self, q, k, v, use_causal_mask=False):\n",
    "        batch_size = tf.shape(k)[0]\n",
    "        q = self.q_linear(q)\n",
    "        k = self.k_linear(k)\n",
    "        v = self.v_linear(v)\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "        attention = scaled_dot_product_attention(q, k, v, use_causal_mask)\n",
    "        concat = self.concat_heads(attention, batch_size)\n",
    "        concat = self.concat_linear(concat)\n",
    "        return concat\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(MultiAttention, self).get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"h\": self.h,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0415fe24",
   "metadata": {},
   "source": [
    "## Blok enkodera\n",
    "<div><img src=\"encoder_block.png\" width=\"400\"/></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f513888",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-11T21:16:16.439695Z",
     "iopub.status.busy": "2023-03-11T21:16:16.439419Z",
     "iopub.status.idle": "2023-03-11T21:16:16.450488Z",
     "shell.execute_reply": "2023-03-11T21:16:16.449472Z"
    },
    "papermill": {
     "duration": 0.023479,
     "end_time": "2023-03-11T21:16:16.452570",
     "exception": false,
     "start_time": "2023-03-11T21:16:16.429091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerEncoderBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.layer_norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-7)\n",
    "        self.layer_norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-7)\n",
    "        self.global_self_attention = MultiAttention(embed_dim=embed_dim, h=num_heads)\n",
    "        self.feed_forward = tf.keras.Sequential(\n",
    "            [tf.keras.layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             tf.keras.layers.Dense(embed_dim),]\n",
    "        )\n",
    "        \n",
    "    def call(self, x):\n",
    "        # Post layer normalization + residual connections\n",
    "        x = self.layer_norm_1(x + self.global_self_attention(q=x, k=x, v=x))\n",
    "        x = self.layer_norm_2(x + self.feed_forward(x))\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7cb0b401",
   "metadata": {},
   "source": [
    "## Blok dekodera\n",
    "<div><img src=\"decoder_block.png\" width=\"350\"/></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efd857c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-11T21:16:16.511448Z",
     "iopub.status.busy": "2023-03-11T21:16:16.510675Z",
     "iopub.status.idle": "2023-03-11T21:16:16.521790Z",
     "shell.execute_reply": "2023-03-11T21:16:16.520904Z"
    },
    "papermill": {
     "duration": 0.023884,
     "end_time": "2023-03-11T21:16:16.523763",
     "exception": false,
     "start_time": "2023-03-11T21:16:16.499879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerDecoderBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.causal_self_attention = MultiAttention(embed_dim=embed_dim, h=num_heads)\n",
    "        self.cross_attention = MultiAttention(embed_dim=embed_dim, h=num_heads)\n",
    "        self.feed_forward = tf.keras.Sequential(\n",
    "            [tf.keras.layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             tf.keras.layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layer_norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-7)\n",
    "        self.layer_norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-7)\n",
    "        self.layer_norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-7)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, x, context):\n",
    "        # Post layer normalization + residual connections\n",
    "        x = self.layer_norm_1(x + self.causal_self_attention(q=x, k=x, v=x, use_causal_mask=True))\n",
    "        x = self.layer_norm_2(x + self.cross_attention(q=x, k=context, v=context))\n",
    "        x = self.layer_norm_3(x + self.feed_forward(x))\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d0777f6",
   "metadata": {},
   "source": [
    "## Wielowarstwowy enkoder\n",
    "<div><img src=\"n.png\" width=\"200\"/></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88f2c895",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, num_layers):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.transformer_encoders = [TransformerEncoderBlock(embed_dim, dense_dim, num_heads) for _ in range(num_layers)]\n",
    "\n",
    "    def call(self, x):\n",
    "        for encoder in self.transformer_encoders:\n",
    "            x = encoder(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87be9c6b",
   "metadata": {},
   "source": [
    "## Wielowarstwowy dekoder\n",
    "<div><img src=\"n.png\" width=\"200\"/></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "369eca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, num_layers):\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "        self.transformer_decoders = [TransformerDecoderBlock(embed_dim, dense_dim, num_heads) for _ in range(num_layers)]\n",
    "\n",
    "    def call(self, x, context):\n",
    "        for encoder in self.transformer_decoders:\n",
    "            x = encoder(x, context)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02b19fcf",
   "metadata": {},
   "source": [
    "## Transformer\n",
    "<div><img src=\"transformer.png\" width=\"500\"/></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8832e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(tf.keras.Model):\n",
    "    def __init__(self, sequence_length, max_tokens, embed_dim, dense_dim, num_heads, encoder_layers, decoder_layers):\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        self.encoder_embedding = PositionalEmbedding(sequence_length, max_tokens, embed_dim)\n",
    "        self.decoder_embedding = PositionalEmbedding(sequence_length, max_tokens, embed_dim)\n",
    "        \n",
    "        self.encoder = TransformerEncoder(embed_dim, dense_dim, num_heads, encoder_layers)\n",
    "        self.decoder = TransformerDecoder(embed_dim, dense_dim, num_heads, decoder_layers)\n",
    "        \n",
    "        # Transformer head\n",
    "        self.dropout = tf.keras.layers.Dropout(0.5)\n",
    "        self.dense = tf.keras.layers.Dense(max_tokens, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        encoder_inputs = inputs['source']\n",
    "        decoder_inputs = inputs['target']\n",
    "        \n",
    "        encoder_embedding = self.encoder_embedding(encoder_inputs)\n",
    "        decoder_embedding = self.decoder_embedding(decoder_inputs)\n",
    "        \n",
    "        encoder_outputs = self.encoder(encoder_embedding)\n",
    "        decoder_outputs = self.decoder(decoder_embedding, encoder_outputs)\n",
    "\n",
    "        x = self.dropout(decoder_outputs, training=training)\n",
    "        x = self.dense(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e888eec",
   "metadata": {},
   "source": [
    "## Learning Rate\n",
    "<div><img src=\"learning_rage.png\" width=\"800\"/></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e02757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, embedding_dim, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.embedding_dim = tf.cast(embedding_dim, dtype=tf.float32)\n",
    "        self.warmup_steps = tf.cast(warmup_steps, dtype=tf.float32)\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, dtype=tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        return tf.math.rsqrt(self.embedding_dim) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c1bf416",
   "metadata": {},
   "source": [
    "## Tworzenie transformera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5bae0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "dense_dim = 4 * embed_dim\n",
    "num_heads = 8\n",
    "encoder_layers = 4\n",
    "decoder_layers = 4\n",
    "\n",
    "transformer = TransformerModel(sequence_length, max_tokens, embed_dim, dense_dim, num_heads, encoder_layers, decoder_layers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ecd86d4e",
   "metadata": {},
   "source": [
    "## Przygotowanie zbioru danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "755c3aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataset(source, target):\n",
    "    source_vectors = source_vectorization(source)\n",
    "    target_vectors = target_vectorization(target)\n",
    "    return ({\n",
    "        \"source\": source_vectors, # encoder_inputs\n",
    "        \"target\": target_vectors[:, :-1], # decoder_inputs (truncate by 1 to keep it at the same length as decoder_outputs, which is shifted right by 1).\n",
    "    }, target_vectors[:, 1:]) # decoder_outputs\n",
    "\n",
    "def make_dataset(df, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((df[\"source\"].values, df[\"target\"].values))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
    "    return dataset.shuffle(100_000).prefetch(16).cache()\n",
    "\n",
    "batch_size = 512\n",
    "train_ds = make_dataset(train_df, batch_size)\n",
    "val_ds = make_dataset(val_df, batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11839858",
   "metadata": {},
   "source": [
    "## Trening!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799926fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c370e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath='../checkpoints/model/',\n",
    "        save_weights_only=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_best_only=True\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c62c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-25 01:10:02.545006: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] ShuffleDatasetV3:7: Filling up shuffle buffer (this may take a while): 31998 of 100000\n",
      "2024-01-25 01:10:11.888566: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] Shuffle buffer filled.\n",
      "2024-01-25 01:10:15.346761: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fe3881f6240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-25 01:10:15.346832: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3080 Laptop GPU, Compute Capability 8.6\n",
      "2024-01-25 01:10:15.363956: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-01-25 01:10:15.817749: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1706141415.906239    5627 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56003/56003 [==============================] - 11995s 213ms/step - loss: 3.0228 - accuracy: 0.5633 - val_loss: 2.2444 - val_accuracy: 0.6468\n",
      "Epoch 2/10\n",
      "56003/56003 [==============================] - 11893s 212ms/step - loss: 2.6110 - accuracy: 0.6075 - val_loss: 2.1575 - val_accuracy: 0.6566\n",
      "Epoch 3/10\n",
      "20573/56003 [==========>...................] - ETA: 1:59:59 - loss: 2.5629 - accuracy: 0.6131"
     ]
    }
   ],
   "source": [
    "transformer.fit(train_ds, \n",
    "                epochs=10, \n",
    "                callbacks=callbacks_list,\n",
    "                validation_data=val_ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea6ae7fd",
   "metadata": {
    "papermill": {
     "duration": 2.824481,
     "end_time": "2023-03-11T22:49:42.234058",
     "exception": false,
     "start_time": "2023-03-11T22:49:39.409577",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Testowanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae276f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vocab = target_vectorization.get_vocabulary()\n",
    "target_index_lookup = dict(zip(range(len(target_vocab)), target_vocab))\n",
    "max_decoded_sentence_length = 30\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = target_vectorization(\n",
    "            [decoded_sentence])[:, :-1]\n",
    "        predictions = transformer(\n",
    "            {'source': tokenized_input_sentence, 'target': tokenized_target_sentence})\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = target_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04caed60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[start] i go tomorrow to a movie [UNK] [end]'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_sequence('Idę jutro do kina na film o ptakach')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e9ef79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[start] the translation is working very important [end]'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decode_sequence('tłumaczenie działa bardzo fajnie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da470dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Będziemy głosować przez podniesienie ręki.\n",
      "[start] we will vote by raising the [UNK] [end]\n",
      "\n",
      "W odniesieniu do min przeciwpiechotnych Kanada może spojrzeć wstecz na pomyślne zawarcie Konwencji o zakazie wykorzystywania, składowania, produkcji i przekazywania min przeciwpiechotnych oraz o ich zniszczeniu na konferencji w Ottawie w dniach 2-4 grudnia 1997 r.\n",
      "[start] with respect to antipersonnel mines the [UNK] may look back to the successful conclusion of the [UNK] convention the [UNK] [UNK] and the transmission of antipersonnel mines and to their\n",
      "\n",
      "a także mając na uwadze, co następuje: w odniesieniu do ust. 2 lit. b), jedna delegacja wyraziła zdecydowane preferencje dla terminu \"będzie\", większość delegacji, które wyraziły swoje opinie, popierała termin \"może\".\n",
      "[start] as well as the [UNK] in respect of article 2 of the commission the delegation expressed a strong preference for the term of the [UNK] that expressed its [UNK] the\n",
      "\n",
      "W art. 114 ust. 2 dodaje się, co następuje:\n",
      "[start] in article [UNK] adds the [UNK] [end]\n",
      "\n",
      "Określili również potrzebę wskaźników wydajności mających zastosowanie do elementów muzealnych wszystkich programów PCH wspomagających muzea, ponieważ pomiar wpływu każdego programu niezależnie nie jest możliwy.\n",
      "[start] also identified the need for performance indicators applicable to museum elements of all [UNK] programs as measuring the impact of each program regardless is not a [UNK] [end]\n",
      "\n",
      "Narzędzie dla płotów i bagna Nowe narzędzie monitorowania powinno okazać się przydatne w innych parkach narodowych Wielkich Jezior, takich jak Point Pelee i Georgian Bay Islands.\n",
      "[start] a tool for the [UNK] and [UNK] new monitoring tool should prove useful in other national parks of the great lakes such as point [UNK] and [UNK] [UNK] [end]\n",
      "\n",
      "Ta strona podsumowuje politykę prywatności i praktyki na stronie internetowej Rady praw autorskich Kanady.\n",
      "[start] this page summarizes the privacy and practice policy on the [UNK] copyright committee [end]\n",
      "\n",
      "Adres Mike McGee:\n",
      "[start] address of [UNK] [UNK] [end]\n",
      "\n",
      ".... z podwójnie wiązanymi atomami tlenu lub siarki bezpośrednio przymocowanymi do pierścienia węglowodorowego [5]. zastąpionego pojedynczymi lub podwójnymi atomami azotu (rodniki nitro 295 / 06) [2]. z pierścieniowymi atomami azotu i zamiennymi atomami azotu przymocowanymi do tego samego łańcucha węglowego, które nie są przerywane pierścieniami węglowodorowymi [5]............... z pierścieniowymi atomami azotu i zamiennymi atomami azotu oddzielonymi pierścieniami węglowodorowymi lub łańcuchami węglowymi przerywanymi pierścieniami węglowodorowymi [5]. zastąpionymi przez atomy węgla posiadające trzy wiązania do hetero atomów z co najwyżej jednym wiązaniem z halogenem, np. rodnikami estrów lub nitryli [5]. [2].. z pierścieniowymi atomami azotu i atomami węgla z trzema wiązaniami z atomami hetero przymocowanymi do tego samego łańcucha węglowego, który nie jest przerywany przez pierścienie węglowodorowe [5].... do łańcucha nasyconego alifatycznie [5]. z pierścieniowymi atomami azotu i atomami węgla z trzema wiązaniami do heteroatomów oddzielonych pierścieniami węglowodorowymi lub łańcuchami węglowymi przerwanymi pierścieniami węglowodorowymi [5] Acylowane na pierścieniowych atomach azotu [2]. przez rodniki pochodzące z kwasów karboksylowych lub ich siarki lub analogów azotu [2]... Radykale pochodzące z kwasów karboksylowych [5]... z alifatycznych kwasów karboksylowych [5]... z aromatycznych kwasów karboksylowych [5].. Radykale pochodzące z kwasów tio- lub tiokarboksylowych [5].. Radykale otrzymywane z analogów azotu kwasów karboksylowych [5] przez rodniki otrzymywane z kwasu węglowego, siarki lub jej analogów azotu [2]... Radykale pochodzące z kwasu węglowego [5]. Radykale pochodzące z analogów siarki kwasu węglowego [5]. Radykale pochodzące z analogów azotu kwasu węglowego [5] z atomami heteroatomami bezpośrednio przymocowanymi do pierścieniowych atomów azotu [2]. Atomy tlenowe [5]. Atomy siarki [5]. Atomy azotu [5] Nieacelowane [5].. acylowane kwasem karboksylowym lub węglowym, lub ich analogami azotu lub siarki [5] 123 123 123 123 123 123 123 123 123 123 123 123 123 12 3 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123\n",
      "[start] [UNK] [UNK] oxygen or sulphur [UNK] directly attached to the [UNK] ring [UNK] single or double [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
      "\n",
      "Ponadto długi proces imigracji i niemożność znalezienia pracy miały znaczący wpływ na decyzje studentów o nieubieganiu się o PR w Kanadzie.\n",
      "[start] further a long immigration process and the inability to find work had a significant impact on students decisions on the [UNK] of [UNK] in the [UNK] [end]\n",
      "\n",
      "Trwające badania potwierdziły, że mitochondrialne (geny ATPase 6 i 8) i jądrowe (rRNA ITS-1) sekwencje DNA (C.)\n",
      "[start] the ongoing study noted that [UNK] [UNK] and [UNK] and nuclear [UNK] [UNK] [UNK] sequences [end]\n",
      "\n",
      "W 2006 r. data rejestracji międzynarodowej została naruszona w 0,03% (tj. 12 z 37,224) wszystkich rejestracji zarejestrowanych w tym roku, a data, którą objęto późniejszą nazwą, została naruszona w 0,16% (tj. 18 z 10,798) wszystkich kolejnych oznaczeń zarejestrowanych w tym roku.\n",
      "[start] in 2006 the date of the international registration was infringed in article 12 of the treaty from all registration registered in this case and the application that was covered by\n",
      "\n",
      "• Ellen Fry Ellen Fry Przewodniczy członek Michel P. Granger Michel P. Granger sekretarz UNOfficial STRESZCZENIE Są to odwołania na mocy podsekcji 67 ust. 1 ustawy celnej od decyzji komisarza kanadyjskiej Agencji Celnej i Skarbowej wydanych na mocy podsekcji 60 ust. 4 ustawy celnej z dnia 11 sierpnia 1999 r.\n",
      "[start] • [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
      "\n",
      "Rzeczywiście, w latach 1985-1999 liczba ta wzrosła z 63 do 82.\n",
      "[start] as in 20022003 this number increased from 63 to [UNK] [end]\n",
      "\n",
      "Odpocznij.\n",
      "[start] [UNK] [end]\n",
      "\n",
      "Personel zapewnił również współpracę między agencjami C & P, WE i rządowymi prowincji w odniesieniu do kilku przypadków wycieku ropy w prowincji.\n",
      "[start] staff also provided cooperation between the [UNK] agencies in canada and the provincial government with respect to several cases of oil spill in canada [end]\n",
      "\n",
      "Przegląd ten koncentrował się na krajowej wymianie informacji CSIS za rok kalendarzowy 1998.\n",
      "[start] this review focused on national exchange of information [UNK] for the calendar year of the [UNK] [end]\n",
      "\n",
      "Odpowiedzi na RFI otrzymano od czterech eksporterów w Indiach i zweryfikowano w drodze spotkań na miejscu w siedzibie eksporterów.\n",
      "[start] response to [UNK] was received from four exporters in the [UNK] and reviewed by place meetings at the [UNK] headquarters [end]\n",
      "\n",
      "Joe Clark, który prowadził silną kampanię i świetnie wypadł podczas debat, ledwo utrzymywał status partii z 12 miejscami i 12,2% głosów.\n",
      "[start] the [UNK] [UNK] which has conducted a strong campaign and has been very much in the [UNK] just maintained the status of the party from 12 sites and [UNK] [end]\n",
      "\n",
      "Oczekuje się, że bardzo godna pochwały inicjatywa skupiająca ministrów gospodarki, finansów i środowiska naturalnego, po powtórzeniu w przyszłości, zostanie rozszerzona na ministrów zdrowia.\n",
      "[start] it is expected that very noteworthy the delegation focusing the ministers of finance and the environment of canada after the recurrence of the [UNK] will be extended to the european\n",
      "\n",
      "The Governance Practices of Institutional Investors (http: / / www.parl.gc.ca / 36 / 1 / parlbus / commbus / senate / come / bank- e / rep- e / rep16nov98- e.htm). W 2001 r. Komitet Przemysłu Papierów Wartościowych ds. Standardów Analityka, pod przewodnictwem Purdy Crawford, opublikował raport \"Setting Analyst Standards\":\n",
      "[start] the regional management of the [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
      "\n",
      "Umowy zostały pomyślnie wynegocjowane z większością 34 pierwszych Narodów, których dotyczy decyzja.\n",
      "[start] the agreement were successfully negotiated with the majority of 34 first countries which are concerned with the [UNK] [end]\n",
      "\n",
      "W rozporządzeniach rozważa się zatrudnienie koordynatora wyborów w celu przeprowadzenia wyborów dyrektorów oraz zapewnienia, by wybory były przeprowadzane w sposób sprawiedliwy i bezstronny, zgodnie z ustawą i rozporządzeniami.\n",
      "[start] the regulations is considered to be the employment of the election coordinator to conduct the election of directors and ensure that the election were conducted in a fair and fair\n",
      "\n",
      "Linia 9804 - Pozostałe składki ubezpieczeniowe Należy podać łączną kwotę składek ubezpieczeniowych związanych z działalnością gospodarczą, które zapłaciłeś, aby ubezpieczyć swoje budynki gospodarstwa, sprzęt gospodarstwa (z wyłączeniem maszyn i pojazdów silnikowych) oraz przerwać działalność.\n",
      "[start] line [UNK] the other insurance contributions should be provided a total amount of insurance contributions related to the business of the [UNK] that is to insure their buildings [UNK] equipment\n",
      "\n",
      "Państwa członkowskie będące odbiorcami oraz osoby trzecie również korygują lub usuwają te dane.\n",
      "[start] member states of recipients and third persons also have been [UNK] or remove these [UNK] [end]\n",
      "\n",
      "Nastolatki i młodzi dorośli, którzy odchodzą ze szkoły, bezrobotni lub nie mają stałych domów, są szczególnie narażeni.\n",
      "[start] teens and young people who go from the [UNK] unemployed or do not have permanent [UNK] are particularly [UNK] [end]\n",
      "\n",
      "Dzięki temu podejściu DND znacznie ściślej współpracuje z innymi departamentami i agencjami, takimi jak Foreign Affairs i Canadian International Development Agency, aby zmaksymalizować skuteczność zaangażowania Kanady na arenie międzynarodowej.\n",
      "[start] through this approach the [UNK] is much closely working with other departments and agencies such as foreign affairs and [UNK] international development to maximize the effectiveness of the [UNK] commitment\n",
      "\n",
      "Niski punkt dla aborygeńskich warunków zdrowotnych i społecznych w Kanadzie przyszedł na początku XX wieku.\n",
      "[start] low point for aboriginal health and social conditions in the [UNK] came at the beginning of [UNK] [end]\n",
      "\n",
      "Dokument - MS Word (Wersja 8.0) tn809.zip, Winzip, 44 kb 1999 06 18 - NBTel Inc. DATA WEJŚCIA W ŻYCIE: 1999 07 18 TYP TARYFOWY:\n",
      "[start] document [UNK] [UNK] [UNK] [UNK] date [UNK] date [UNK] date [UNK] [end]\n",
      "\n",
      "Więcej szczegółów w instrukcji łączenia.\n",
      "[start] more details in the [UNK] instructions [end]\n",
      "\n",
      "• Uaktualnić nasz traktat podatkowy ze Stanami Zjednoczonymi w celu zmniejszenia barier podatkowych dla przepływu kapitału między naszymi krajami.\n",
      "[start] • update our tax treaty from the member states to reduce tax barriers to the flow of capital between our countries [end]\n",
      "\n",
      "Nie zalecamy wprowadzenia na tym etapie prawodawstwa z wielu innych powodów.\n",
      "[start] we not recommend the introduction of this stage of legislation with many other countries [end]\n",
      "\n",
      "Po zakończeniu DAAP odnowiony zostanie plan strategiczny DFO i PRAS oraz opracowany i przedstawiony zostanie kompleksowy nowy SDS.\n",
      "[start] after the end of the [UNK] the strategic plan will be renewed for the [UNK] and presses and the developed and a comprehensive new [UNK] will be presented [end]\n",
      "\n",
      "• Nie trzeba gromadzić surowców w młynach i zakładach Dock 3 - dla wydobytych produktów węglowych i energetycznych na Dock 3, produkty węglowe i energetyczne przepływają bezpośrednio z wagonu kolejowego lub składowania ziemi do statków Wielkich Jezior.\n",
      "[start] • not to collect raw materials in mills and dock plants 3 [UNK] for processed carbon and energy products on the [UNK] [UNK] and energy products flow directly from the\n",
      "\n",
      "SSR; Sport Service Review; Sport Services Review Examen des services du sport (n.m.); ESS (n.m.)\n",
      "[start] [UNK] sport service [UNK] sport services review [UNK] des services du sport [UNK] [UNK] [end]\n",
      "\n",
      "CCME (Kanadyjska Rada Ministrów Środowiska), 1996a.\n",
      "[start] [UNK] [UNK] [UNK] [UNK] [end]\n",
      "\n",
      "Poprzez wyznaczanie celów UE i państwa członkowskie wysyłają jasne sygnały do całego przemysłu i sektora energii elektrycznej, w szczególności inwestorów i przedsiębiorców, że istnieją obecnie realne długoterminowe możliwości dla odnawialnych źródeł energii.\n",
      "[start] through the designation of [UNK] and member states send clear signals to the entire industry and the energy sector of the [UNK] in particular investors and the fact that there\n",
      "\n",
      "Schizofrenia (Walk the World) * 31 World No- Tobacco Dzień Miesiąc Czerwiec ALS Miesiąc świadomości (choroba Lou Gehriga) National Spina Bifida i Hydrocephalus Świadomość Miesiąc Seniorów Miesiąc świadomości Stroke Miesiąc\n",
      "[start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
      "\n",
      "Inne korporacje koronne należące do PCH Portfolio są zobowiązane przez ustawodawstwo do przedstawienia swoich planów korporacyjnych Parlamentowi, jak również streszczenia planu dla Izby Gmin.\n",
      "[start] other crown corporations belonging to the [UNK] portfolio are required by legislation to provide their corporate plans to the commission as well as the summary of the plan for the\n",
      "\n",
      "\"Naszym zadaniem jest zapewnienie, że recepta jest ważna, sprawdzić interakcje leków, wyjaśnić zastosowania i niekorzystne skutki dla pacjentów i zapewnić optymalną opiekę farmaceutyczną\".\n",
      "[start] the first task is that the prescription is to check the [UNK] interactions explain the application and adverse effects for patients and provide optimal health care [end]\n",
      "\n",
      "• Ottawa Citizen - 25 lipca 2006 - Dyrektor Naukowy SCN, dr Michael Rudnicki, i były Dyrektor Naukowy, dr Ron Worton są cytowane w artykule na temat otwarcia nowego Centrum Badań Komórki Sproct Stem w Ottawie.\n",
      "[start] • [UNK] [UNK] july 25 2006 the scientific director of the [UNK] dr [UNK] and was the director of [UNK] dr [UNK] [UNK] are cited in the article on the\n",
      "\n",
      "7.1.10 77% urzędników ds. bezpieczeństwa ogólnego badanych podczas oceny KSR programu bezpieczeństwa ogólnego z 2002 r. stwierdziło, że obowiązki GSO nie są w stanie wykonywać ze względu na brak czasu lub środków.\n",
      "[start] [UNK] [UNK] of general security officers tested during the [UNK] of the 2002 general security program the commission noted that the responsibilities of the commission are not able to perform\n",
      "\n",
      "Celem tego programu była współpraca z agencjami zewnętrznymi w celu ustalenia, czy wszyscy sportowcy przyjeżdżający do Salt Lake Games byli testowani pod kątem zażywania narkotyków przed przyjazdem do Salt Lake w lutym 2002 r.\n",
      "[start] the objective of this program was to work with external agencies to determine whether all athletes coming to the [UNK] lake were [UNK] for drug use before the [UNK] [UNK]\n",
      "\n",
      "Odnoszę się do pańskiego listu z dnia 27 sierpnia 1992 r., w którym zwrócił pan uwagę Europejskiego Komitetu ds. Zapobiegania Torturom oraz Nieludzkiemu lub poniżającemu traktowaniu lub karaniu (CPT) na projekt Protokołu fakultatywnego do Konwencji Narodów Zjednoczonych przeciwko Torturom i Innemu Okrutnemu, Nieludzkiemu lub poniżającemu traktowaniu lub karaniu, zaproponowany przez rząd Kostarican dnia 22 stycznia 1991 r.\n",
      "[start] please refer to your letter of 27 august 1992 in which mr [UNK] said the european committee of torture prevention or degrading treatment or punishment of the [UNK] to the\n",
      "\n",
      "Przez lata robiła rysunki.\n",
      "[start] by years he had done the [UNK] [end]\n",
      "\n",
      "Podsumowując, w 1998 r. wiele miejsc w Hamilton Harbour miało stężenia amoniaku niezjonizowanego, które wynosiły do 0,11 mg / L. Niezjonizowane stężenia amoniaku w innych obszarach były wyższe niż stężenia, które są ogólnie bezpieczne dla organizmów wodnych.\n",
      "[start] however in 1998 many sites in [UNK] [UNK] were [UNK] concentrations of ammonia [UNK] which were [UNK] [UNK] [UNK] [UNK] concentrations of ammonia in other areas were higher than [UNK]\n",
      "\n",
      "\"Muzea takie jak Centrum Kosmiczne MacMillan mogą odegrać ważną rolę w kształceniu Kanadyjczyków poprzez prezentowanie informacji o zmianach klimatycznych w ciekawy, interesujący sposób\".\n",
      "[start] the [UNK] such as the [UNK] space centre may play a important role in learning [UNK] by presenting information on climate change in the [UNK] of the interesting [UNK] [end]\n",
      "\n",
      "Przesunięcie realizacji planowanego programu uboju borsuków na rok do czasu wydania przez Stały Komitet opinii na temat tego, czy stanowi ono naruszenie zobowiązań Zjednoczonego Królestwa wynikających z konwencji.\n",
      "[start] the transfer of the implementation of the planned [UNK] slaughter program for the year until the permanent opinion committee on the fact that it is a violation of the member\n",
      "\n",
      "Nowa Kanadyjska Sieć Budownictwa i Nauk Zdrowotnych poprawi zdrowie Kanadyjczyków, łącząc naukowców w celu współpracy na rzecz poprawy środowiska budowlanego.\n",
      "[start] new canadian construction and health science network will improve the health of canadians combining researchers to cooperate to improve the environmental environmental [end]\n",
      "\n",
      "• Przeniesienie na osoby wzrosło o 3,9%, co wynika z wyższych świadczeń dla osób starszych, co odzwierciedla wzrost liczby osób kwalifikujących się do świadczeń i wyższych średnich świadczeń, które są indeksowane do inflacji, oraz wzrost wypłat świadczeń z tytułu EI.\n",
      "[start] • transfer for individuals increased by [UNK] that is due to higher benefits for persons with a increase in the number of persons eligible for benefits and higher average rates\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    random_index = np.random.randint(0, len(test_df))\n",
    "    input_sentence = test_df[\"source\"].iloc[random_index]\n",
    "    print(input_sentence)\n",
    "    print(decode_sequence(input_sentence))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5693.346436,
   "end_time": "2023-03-11T22:50:26.592976",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-11T21:15:33.246540",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
