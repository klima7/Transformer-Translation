{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05a768a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T21:56:23.313623Z",
     "iopub.status.busy": "2023-03-07T21:56:23.313156Z",
     "iopub.status.idle": "2023-03-07T21:56:23.320534Z",
     "shell.execute_reply": "2023-03-07T21:56:23.318865Z",
     "shell.execute_reply.started": "2023-03-07T21:56:23.313584Z"
    },
    "papermill": {
     "duration": 0.009067,
     "end_time": "2023-03-11T21:15:41.733022",
     "exception": false,
     "start_time": "2023-03-11T21:15:41.723955",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Transformer from scratch\n",
    "\n",
    "This notebook builds a basic **Encoder-Decoder** variant of the Transformer architecture from scratch (Multi-Head Attention, Scaled Dot-Product Attention and Causal Masking included) in TensorFlow.\n",
    "\n",
    "It serves to understand how each part of the Transformer works and how they all fit together.\n",
    "\n",
    "The Transformer is then tested on a simple seq2seq task : **translating sentences from English to French**.\n",
    "\n",
    "[<img src=\"https://ar5iv.labs.arxiv.org/html/1706.03762/assets/Figures/ModalNet-21.png\" width=\"300\">](https://arxiv.org/abs/1706.03762)\n",
    "\n",
    "**Steps :**\n",
    "1. [Preparing the data](#Preparing-the-data)\n",
    "2. [Building the Transformer](#Building-the-Transformer)\n",
    "3. [Training the Transformer](#Training-the-Transformer)\n",
    "4. [Testing the Transformer](#Testing-the-Transformer)\n",
    "    \n",
    "*[Credits and stuff](#Credits-and-stuff)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e491dc58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-11T21:15:41.750311Z",
     "iopub.status.busy": "2023-03-11T21:15:41.749655Z",
     "iopub.status.idle": "2023-03-11T21:15:48.333591Z",
     "shell.execute_reply": "2023-03-11T21:15:48.332497Z"
    },
    "papermill": {
     "duration": 6.595399,
     "end_time": "2023-03-11T21:15:48.336261",
     "exception": false,
     "start_time": "2023-03-11T21:15:41.740862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_131541/4184736172.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "2024-01-23 23:10:26.724229: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-23 23:10:26.760526: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-23 23:10:26.760637: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-23 23:10:26.762262: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-23 23:10:26.770551: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-23 23:10:27.760819: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import string\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a29abd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-11T21:15:48.353919Z",
     "iopub.status.busy": "2023-03-11T21:15:48.353342Z",
     "iopub.status.idle": "2023-03-11T21:15:48.539046Z",
     "shell.execute_reply": "2023-03-11T21:15:48.537975Z"
    },
    "papermill": {
     "duration": 0.197258,
     "end_time": "2023-03-11T21:15:48.541669",
     "exception": false,
     "start_time": "2023-03-11T21:15:48.344411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.15.0\n",
      "\n",
      "GPU is AVAILABLE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-23 23:10:32.370613: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-23 23:10:32.513014: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-23 23:10:32.513412: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print()\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"AVAILABLE\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f9ec5f",
   "metadata": {
    "papermill": {
     "duration": 0.007735,
     "end_time": "2023-03-11T21:15:48.557506",
     "exception": false,
     "start_time": "2023-03-11T21:15:48.549771",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b976abf",
   "metadata": {
    "papermill": {
     "duration": 0.007585,
     "end_time": "2023-03-11T21:15:48.572882",
     "exception": false,
     "start_time": "2023-03-11T21:15:48.565297",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"color:#000; display:fill; border-radius:8px; background-color:#000; font-size:125%;\">\n",
    "    <p style=\"padding: 8px 12px 8px 12px; color:#fff;\"><b>Reading the data</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85ddef18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-11T21:15:48.590891Z",
     "iopub.status.busy": "2023-03-11T21:15:48.589444Z",
     "iopub.status.idle": "2023-03-11T21:15:49.100476Z",
     "shell.execute_reply": "2023-03-11T21:15:49.099058Z"
    },
    "papermill": {
     "duration": 0.522132,
     "end_time": "2023-03-11T21:15:49.102834",
     "exception": false,
     "start_time": "2023-03-11T21:15:48.580702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14953</th>\n",
       "      <td>Etykieta zawiera chińskie znaki \"China Organic...</td>\n",
       "      <td>[start] The label contains Chinese characters ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26233</th>\n",
       "      <td>Château des Charmes, Niagara- on-the- Lake, On...</td>\n",
       "      <td>[start] Château des Charmes, Niagara-on-the-La...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93011</th>\n",
       "      <td>• Świadomy udział lub wkład w działalność grup...</td>\n",
       "      <td>[start] • Knowingly participating in or contri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76172</th>\n",
       "      <td>Canada Mortgage and Housing Corporation (CMHC)...</td>\n",
       "      <td>[start] Canada Mortgage and Housing Corporatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41864</th>\n",
       "      <td>• Regionalny profil rolno-spożywczy - Przegląd...</td>\n",
       "      <td>[start] • Agri-Food Regional Profile - Statist...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  source  \\\n",
       "14953  Etykieta zawiera chińskie znaki \"China Organic...   \n",
       "26233  Château des Charmes, Niagara- on-the- Lake, On...   \n",
       "93011  • Świadomy udział lub wkład w działalność grup...   \n",
       "76172  Canada Mortgage and Housing Corporation (CMHC)...   \n",
       "41864  • Regionalny profil rolno-spożywczy - Przegląd...   \n",
       "\n",
       "                                                  target  \n",
       "14953  [start] The label contains Chinese characters ...  \n",
       "26233  [start] Château des Charmes, Niagara-on-the-La...  \n",
       "93011  [start] • Knowingly participating in or contri...  \n",
       "76172  [start] Canada Mortgage and Housing Corporatio...  \n",
       "41864  [start] • Agri-Food Regional Profile - Statist...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the file path\n",
    "file_path = '../data/en-pl.csv'\n",
    "\n",
    "# read the data\n",
    "df = pd.read_csv(file_path).truncate(after=100_000)\n",
    "df['source'] = df['pl']\n",
    "\n",
    "# let's add an initial “seed” token ([start]) and a stop token ([end]) to each target sentence.\n",
    "df['target'] = df['en'].apply(lambda x: '[start] ' + x + ' [end]')\n",
    "\n",
    "df = df.drop(['pl', 'en'], axis=1)\n",
    "\n",
    "# display a few random samples\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa08da9",
   "metadata": {
    "papermill": {
     "duration": 0.007974,
     "end_time": "2023-03-11T21:15:49.119916",
     "exception": false,
     "start_time": "2023-03-11T21:15:49.111942",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"color:#000; display:fill; border-radius:8px; background-color:#000; font-size:125%;\">\n",
    "    <p style=\"padding: 8px 12px 8px 12px; color:#fff;\"><b>Shuffling the data and splitting it into train, validation, and test sets</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b31d06e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-11T21:15:49.139118Z",
     "iopub.status.busy": "2023-03-11T21:15:49.137517Z",
     "iopub.status.idle": "2023-03-11T21:15:49.324222Z",
     "shell.execute_reply": "2023-03-11T21:15:49.320248Z"
    },
    "papermill": {
     "duration": 0.199592,
     "end_time": "2023-03-11T21:15:49.327853",
     "exception": false,
     "start_time": "2023-03-11T21:15:49.128261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# shuffle the data\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# split the data into train, validation, and test sets\n",
    "train_size = int(len(df) * 0.7)\n",
    "val_size = int(len(df) * 0.2)\n",
    "test_size = int(len(df) * 0.1)\n",
    "\n",
    "train_df = df[:train_size]\n",
    "val_df = df[train_size:train_size+val_size]\n",
    "test_df = df[train_size+val_size:]\n",
    "\n",
    "# display the data sets representations using a pie chart just to see the distribution of the data\n",
    "labels = 'Train', 'Validation', 'Test'\n",
    "sizes = [len(train_df), len(val_df), len(test_df)]\n",
    "explode = (0.1, 0, 0)\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "ax1.axis('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e095629",
   "metadata": {
    "papermill": {
     "duration": 0.021137,
     "end_time": "2023-03-11T21:15:49.371778",
     "exception": false,
     "start_time": "2023-03-11T21:15:49.350641",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"color:#000; display:fill; border-radius:8px; background-color:#000; font-size:125%;\">\n",
    "    <p style=\"padding: 8px 12px 8px 12px; color:#fff;\"><b>Standardizing, tokenizing and indexing the data</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8b0536",
   "metadata": {
    "papermill": {
     "duration": 0.008313,
     "end_time": "2023-03-11T21:15:49.398992",
     "exception": false,
     "start_time": "2023-03-11T21:15:49.390679",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "First, we need to parse our raw text data and vectorize it.\n",
    "\n",
    "To keep things simple, we will first limit our vocabulary using the **max_tokens** parameter. We will also limit the length of each sentence using the **sequence_length** parameter.\n",
    "\n",
    "Each sentence will be standardized, tokenized by word, and then indexed by token.\n",
    "\n",
    "This will result in a batch of vectors of tokens, stored in a **2D** matrix of shape [(batch_size, **sequence_length**)]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa29ac95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-11T21:15:49.417259Z",
     "iopub.status.busy": "2023-03-11T21:15:49.416961Z",
     "iopub.status.idle": "2023-03-11T21:16:10.211774Z",
     "shell.execute_reply": "2023-03-11T21:16:10.210723Z"
    },
    "papermill": {
     "duration": 20.806875,
     "end_time": "2023-03-11T21:16:10.214442",
     "exception": false,
     "start_time": "2023-03-11T21:15:49.407567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_tokens = 12000\n",
    "sequence_length = 15\n",
    "\n",
    "# define a custom standardization function that convert to lowercase and strips all punctuations except \"[\" and \"]\" (so we can tell apart \"start\" from \"[start]\").\n",
    "strip_chars = string.punctuation\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    " \n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(\n",
    "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
    "\n",
    "# tokenize the data using our custom standardization function\n",
    "source_vectorization = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "target_vectorization = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length + 1, # add +1 token to our target sentences since they'll be shifted right by 1 during training\n",
    "    standardize=custom_standardization,\n",
    ")\n",
    "\n",
    "# index all tokens in the source and target sentences\n",
    "train_source_texts = train_df['source'].values\n",
    "train_target_texts = train_df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf1408b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_vectorization.adapt(train_source_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb7ec89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vectorization.adapt(train_target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7bfc6d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-11T21:16:10.234873Z",
     "iopub.status.busy": "2023-03-11T21:16:10.234550Z",
     "iopub.status.idle": "2023-03-11T21:16:13.403030Z",
     "shell.execute_reply": "2023-03-11T21:16:13.401994Z"
    },
    "papermill": {
     "duration": 3.18088,
     "end_time": "2023-03-11T21:16:13.405459",
     "exception": false,
     "start_time": "2023-03-11T21:16:10.224579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source texts (one random sample): Office of the Commissioner for Federal Judicial Affairs 3.\n",
      "Target texts (one random sample): [start] Office of the Commissioner for Federal Judicial Affairs  3. [end]\n",
      "Source vectors (one random sample): tf.Tensor(\n",
      "[1058   44   73 3948  161 1415 2971  663  109    0    0    0    0    0\n",
      "    0], shape=(15,), dtype=int64)\n",
      "Target vectors (one random sample): tf.Tensor(\n",
      "[   3  263    5    2  334   10  132 1042 5298  191    4    0    0    0\n",
      "    0    0], shape=(16,), dtype=int64)\n",
      "Source decoded texts (one random sample): office of the commissioner for federal judicial affairs 3       \n",
      "Target decoded texts (one random sample): [start] office of the commissioner for federal judicial affairs  3 [end]      \n"
     ]
    }
   ],
   "source": [
    "# display a random sample before and after vectorization just to test the vectorization\n",
    "random_sample = random.randint(0, len(train_df))\n",
    "print(\"Source texts (one random sample):\", train_source_texts[random_sample])\n",
    "print(\"Target texts (one random sample):\", train_target_texts[random_sample])\n",
    "print(\"Source vectors (one random sample):\", source_vectorization(train_source_texts[random_sample]))\n",
    "print(\"Target vectors (one random sample):\", target_vectorization(train_target_texts[random_sample]))\n",
    "\n",
    "# display the decoding of the vectorized text (from vector back to text) just to test the vectorization\n",
    "source_decoded_text = ''\n",
    "for i in range(len(source_vectorization(train_source_texts[random_sample]))):\n",
    "    source_decoded_text += source_vectorization.get_vocabulary()[source_vectorization(train_source_texts[random_sample])[i]] + ' '\n",
    "print(\"Source decoded texts (one random sample):\", source_decoded_text)\n",
    "\n",
    "target_decoded_text = ''\n",
    "for i in range(len(target_vectorization(train_target_texts[random_sample]))):\n",
    "    target_decoded_text += target_vectorization.get_vocabulary()[target_vectorization(train_target_texts[random_sample])[i]] + ' '\n",
    "print(\"Target decoded texts (one random sample):\", target_decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba63e63c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-11T21:16:13.427630Z",
     "iopub.status.busy": "2023-03-11T21:16:13.425760Z",
     "iopub.status.idle": "2023-03-11T21:16:14.137677Z",
     "shell.execute_reply": "2023-03-11T21:16:14.135335Z"
    },
    "papermill": {
     "duration": 0.725633,
     "end_time": "2023-03-11T21:16:14.140339",
     "exception": false,
     "start_time": "2023-03-11T21:16:13.414706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source vectors (shape): (70000, 15)\n",
      "Target vectors (shape): (70000, 16)\n"
     ]
    }
   ],
   "source": [
    "# display the shape of our vectorized data\n",
    "train_source_vectors = source_vectorization(train_source_texts)\n",
    "train_target_vectors = target_vectorization(train_target_texts)\n",
    "print(\"Source vectors (shape):\", train_source_vectors.shape)\n",
    "print(\"Target vectors (shape):\", train_target_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cf2b3b",
   "metadata": {
    "papermill": {
     "duration": 0.010437,
     "end_time": "2023-03-11T21:16:14.161602",
     "exception": false,
     "start_time": "2023-03-11T21:16:14.151165",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Building the Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3efbb9",
   "metadata": {
    "papermill": {
     "duration": 0.010258,
     "end_time": "2023-03-11T21:16:14.182397",
     "exception": false,
     "start_time": "2023-03-11T21:16:14.172139",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"color:#000; display:fill; border-radius:8px; background-color:#000; font-size:125%;\">\n",
    "    <p style=\"padding: 8px 12px 8px 12px; color:#fff;\"><b>Positional Embedding</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb12185",
   "metadata": {
    "papermill": {
     "duration": 0.010226,
     "end_time": "2023-03-11T21:16:14.203184",
     "exception": false,
     "start_time": "2023-03-11T21:16:14.192958",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In order for our Transformer to be aware of the word order in each sentence, we must add some positional information to the data. **Words must become position-aware.**\n",
    "\n",
    "First, each token in our vectors will be embedded in a low-dimensional vector (the dimensionality of the embedding space is defined by the **embedding_size** parameter).\n",
    "\n",
    "Secondly, position information (info on where each word stands in the sentence) will be created and added to the embeddings.\n",
    "\n",
    "This will result in a batch of vectors of positional embeddings, stored in a **3D** matrix of shape [(batch_size, sequence_length, **embedding_size**)]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2489cab4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-11T21:16:14.226341Z",
     "iopub.status.busy": "2023-03-11T21:16:14.225469Z",
     "iopub.status.idle": "2023-03-11T21:16:14.235651Z",
     "shell.execute_reply": "2023-03-11T21:16:14.234365Z"
    },
    "papermill": {
     "duration": 0.024289,
     "end_time": "2023-03-11T21:16:14.237957",
     "exception": false,
     "start_time": "2023-03-11T21:16:14.213668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = tf.keras.layers.Embedding(input_dim=input_dim, output_dim=output_dim) # token embedding layer\n",
    "        self.position_embeddings = tf.keras.layers.Embedding(input_dim=sequence_length, output_dim=output_dim) # position embedding layer\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        embedded_tokens = self.token_embeddings(inputs) # embed the tokens\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1) # create the positional information\n",
    "        embedded_positions = self.position_embeddings(positions) # embed the positions \n",
    "        return embedded_tokens + embedded_positions # add the token and position embeddings to create the positional embeddings\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(PositionalEmbedding, self).get_config()\n",
    "        config.update({\n",
    "            \"input_dim\": self.input_dim,\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92c58ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-11T21:16:14.260901Z",
     "iopub.status.busy": "2023-03-11T21:16:14.259978Z",
     "iopub.status.idle": "2023-03-11T21:16:14.417654Z",
     "shell.execute_reply": "2023-03-11T21:16:14.416135Z"
    },
    "papermill": {
     "duration": 0.171469,
     "end_time": "2023-03-11T21:16:14.419913",
     "exception": false,
     "start_time": "2023-03-11T21:16:14.248444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display a random sample before and after embbeding just to test our class\n",
    "\n",
    "embed_dim = 64\n",
    "\n",
    "train_source_embedded = PositionalEmbedding(\n",
    "    sequence_length=sequence_length,\n",
    "    input_dim=max_tokens,\n",
    "    output_dim=embed_dim,\n",
    "    name=\"source_embedding\",\n",
    ") (train_source_vectors)\n",
    "\n",
    "train_target_embedded = PositionalEmbedding(\n",
    "    sequence_length=sequence_length,\n",
    "    input_dim=max_tokens,\n",
    "    output_dim=embed_dim,\n",
    "    name=\"target_embedding\",\n",
    ") (train_source_vectors)\n",
    "\n",
    "random_sample = random.randint(0, len(train_df))\n",
    "print(\"Source texts (one random sample):\", train_source_texts[random_sample])\n",
    "print(\"Target texts (one random sample):\", train_target_texts[random_sample])\n",
    "print(\"Source vectors (one random sample):\", source_vectorization(train_source_texts[random_sample]))\n",
    "print(\"Target vectors (one random sample):\", target_vectorization(train_target_texts[random_sample]))\n",
    "print(\"Source embedded vectors (one random sample):\", train_source_embedded[random_sample])\n",
    "print(\"Target embedded vectors (one random sample):\", train_target_embedded[random_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de99ff68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-11T21:16:14.440240Z",
     "iopub.status.busy": "2023-03-11T21:16:14.439932Z",
     "iopub.status.idle": "2023-03-11T21:16:14.445036Z",
     "shell.execute_reply": "2023-03-11T21:16:14.444082Z"
    },
    "papermill": {
     "duration": 0.017393,
     "end_time": "2023-03-11T21:16:14.447230",
     "exception": false,
     "start_time": "2023-03-11T21:16:14.429837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source embedded vectors (shape): (70000, 15, 64)\n",
      "Target embedded vectors (shape): (70000, 15, 64)\n"
     ]
    }
   ],
   "source": [
    "# display the shape of our embedded data just to test the class\n",
    "print(\"Source embedded vectors (shape):\", train_source_embedded.shape)\n",
    "print(\"Target embedded vectors (shape):\", train_target_embedded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6874ae",
   "metadata": {
    "papermill": {
     "duration": 0.008999,
     "end_time": "2023-03-11T21:16:14.465350",
     "exception": false,
     "start_time": "2023-03-11T21:16:14.456351",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"color:#000; display:fill; border-radius:8px; background-color:#000; font-size:125%;\">\n",
    "    <p style=\"padding: 8px 12px 8px 12px; color:#fff;\"><b>The Attention mechanism</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62693d6e",
   "metadata": {
    "papermill": {
     "duration": 0.008956,
     "end_time": "2023-03-11T21:16:14.483557",
     "exception": false,
     "start_time": "2023-03-11T21:16:14.474601",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The goal here is to make each of our words (positional embeddings at this point) aware of the other words surrounding them. **Words must become context-aware.**\n",
    "\n",
    "The implementation of the Attention mechanism involves the following 3 steps : \n",
    "\n",
    "- Causal Masking\n",
    "- Scaled Dot-Product Attention\n",
    "- Multi-Head Attention\n",
    "\n",
    "In practice, we could just use **tf.keras.layers.MultiHeadAttention** instead of building it from scratch, but let's do it anyway! 😒"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4065aa",
   "metadata": {
    "papermill": {
     "duration": 0.008946,
     "end_time": "2023-03-11T21:16:14.501745",
     "exception": false,
     "start_time": "2023-03-11T21:16:14.492799",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"color:#fff; display:fill; border-width:1px; border-color:#000; font-size:125%;\">\n",
    "    <p style=\"border-style:solid; border-radius:8px; background-color:#fff; padding: 8px 12px 8px 12px; color:#000;\"><b>Causal Masking</b></p>\n",
    "</div>"
   ]
  },
  {
   "attachments": {
    "0238767f-d97d-4c4c-9238-24a5ac730526.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "bdf6eeee",
   "metadata": {
    "papermill": {
     "duration": 0.009627,
     "end_time": "2023-03-11T21:16:14.520504",
     "exception": false,
     "start_time": "2023-03-11T21:16:14.510877",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "Since our words will now be context-aware (aware of words before **and** after them in the sentence), we need a way to mask those *after-words* when needed be (i.e. during training).\n",
    "\n",
    "![image.png](attachment:0238767f-d97d-4c4c-9238-24a5ac730526.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6603854e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-11T21:16:14.540900Z",
     "iopub.status.busy": "2023-03-11T21:16:14.540100Z",
     "iopub.status.idle": "2023-03-11T21:16:14.548405Z",
     "shell.execute_reply": "2023-03-11T21:16:14.547426Z"
    },
    "papermill": {
     "duration": 0.020436,
     "end_time": "2023-03-11T21:16:14.550520",
     "exception": false,
     "start_time": "2023-03-11T21:16:14.530084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# credits to OpenAI for that one (https://github.com/openai/gpt-2/blob/master/src/model.py)\n",
    "\n",
    "def shape_list(x):\n",
    "    \"\"\"Deal with dynamic shape in tensorflow cleanly.\"\"\"\n",
    "    static = x.shape.as_list()\n",
    "    dynamic = tf.shape(x)\n",
    "    return [dynamic[i] if s is None else s for i, s in enumerate(static)]\n",
    "\n",
    "def attention_mask(nd, ns, *, dtype):\n",
    "    \"\"\"1's in the lower triangle, counting from the lower right corner.\n",
    "    Same as tf.matrix_band_part(tf.ones([nd, ns]), -1, ns-nd), but doesn't produce garbage on TPUs.\n",
    "    \"\"\"\n",
    "    i = tf.range(nd)[:,None]\n",
    "    j = tf.range(ns)\n",
    "    m = i >= j - ns + nd\n",
    "    return tf.cast(m, dtype)\n",
    "\n",
    "def mask_attn_weights(w):\n",
    "    # w has shape [batch, heads, dst_sequence, src_sequence], where information flows from src to dst.\n",
    "    _, _, nd, ns = shape_list(w)\n",
    "    b = attention_mask(nd, ns, dtype=w.dtype)\n",
    "    b = tf.reshape(b, [1, 1, nd, ns])\n",
    "    w = w*b - tf.cast(1e10, w.dtype)*(1-b)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5c8960f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-11T21:16:14.571219Z",
     "iopub.status.busy": "2023-03-11T21:16:14.570947Z",
     "iopub.status.idle": "2023-03-11T21:16:14.595015Z",
     "shell.execute_reply": "2023-03-11T21:16:14.594096Z"
    },
    "papermill": {
     "duration": 0.03618,
     "end_time": "2023-03-11T21:16:14.597181",
     "exception": false,
     "start_time": "2023-03-11T21:16:14.561001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked attention weights: tf.Tensor(\n",
      "[[[[ 1.10010505e-01 -1.00000000e+10 -1.00000000e+10 -1.00000000e+10\n",
      "    -1.00000000e+10]\n",
      "   [ 1.37032866e-01  5.97499609e-02 -1.00000000e+10 -1.00000000e+10\n",
      "    -1.00000000e+10]\n",
      "   [ 5.89616060e-01  2.53011703e-01  5.05310416e-01 -1.00000000e+10\n",
      "    -1.00000000e+10]\n",
      "   [ 3.54104280e-01  7.40357876e-01  5.82142830e-01  9.28657174e-01\n",
      "    -1.00000000e+10]\n",
      "   [ 4.83971119e-01  7.50534177e-01  1.58786178e-01  3.03326011e-01\n",
      "     7.28219748e-01]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# display the causal masking of a random tensor just to test the function\n",
    "random_tensor = tf.random.uniform(shape=(1, 1, 5, 5), minval=0, maxval=1, dtype=tf.float32)\n",
    "print(\"Masked attention weights:\", mask_attn_weights(random_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343933e5",
   "metadata": {
    "papermill": {
     "duration": 0.009065,
     "end_time": "2023-03-11T21:16:14.615686",
     "exception": false,
     "start_time": "2023-03-11T21:16:14.606621",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"color:#fff; display:fill; border-width:1px; border-color:#000; font-size:125%;\">\n",
    "    <p style=\"border-style:solid; border-radius:8px; background-color:#fff; padding: 8px 12px 8px 12px; color:#000;\"><b>Scaled Dot-Product Attention</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b90dcb",
   "metadata": {
    "papermill": {
     "duration": 0.009181,
     "end_time": "2023-03-11T21:16:14.634262",
     "exception": false,
     "start_time": "2023-03-11T21:16:14.625081",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This function is what makes our words context-aware.\n",
    "\n",
    "We want to compare each word with every other words around them and take note of how *related* they are. Technically, this process can be described as \"mapping a query and a set of key-value pairs to an output\". It can be summarized as follows :\n",
    "- We take a **Q**uery of elements.\n",
    "- For each element in the **Q**uery, we score how much that element is related to every **K**ey (This is done using a compatibility function : MatMul). If needed be, Causal Masking will be applied here.\n",
    "- Then, we use these relationship scores to weight a sum of **V**alues, which will be our new context-aware representations.\n",
    "\n",
    "[<img src=\"https://ar5iv.labs.arxiv.org/html/1706.03762/assets/Figures/ModalNet-19.png\" width=\"120\">](https://arxiv.org/abs/1706.03762)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "914b9e51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-11T21:16:14.654544Z",
     "iopub.status.busy": "2023-03-11T21:16:14.653760Z",
     "iopub.status.idle": "2023-03-11T21:16:14.659883Z",
     "shell.execute_reply": "2023-03-11T21:16:14.658961Z"
    },
    "papermill": {
     "duration": 0.01822,
     "end_time": "2023-03-11T21:16:14.661905",
     "exception": false,
     "start_time": "2023-03-11T21:16:14.643685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, use_causal_mask=False):\n",
    "    d_k = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scores = tf.matmul(q, k, transpose_b=True) # Matmul of Q and K\n",
    "    scaled_scores = scores / tf.math.sqrt(d_k) # Scale\n",
    "    if use_causal_mask:\n",
    "        scaled_scores = mask_attn_weights(scaled_scores) # Mask (opt.)\n",
    "    weights = tf.nn.softmax(scaled_scores, axis=-1) # SoftMax\n",
    "    output = tf.matmul(weights, v) # Matmul of SoftMax and V\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb6af42d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-11T21:16:14.681651Z",
     "iopub.status.busy": "2023-03-11T21:16:14.681397Z",
     "iopub.status.idle": "2023-03-11T21:16:16.305932Z",
     "shell.execute_reply": "2023-03-11T21:16:16.304450Z"
    },
    "papermill": {
     "duration": 1.637083,
     "end_time": "2023-03-11T21:16:16.308251",
     "exception": false,
     "start_time": "2023-03-11T21:16:14.671168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled dot product attention (shape): (70000, 1, 15, 64)\n"
     ]
    }
   ],
   "source": [
    "# display the shape of our attention output just to test the function\n",
    "input = train_source_embedded\n",
    "input = tf.expand_dims(input, axis=1)\n",
    "print(\"Scaled dot product attention (shape):\", scaled_dot_product_attention(input, input, input, use_causal_mask=True).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23250fa",
   "metadata": {
    "papermill": {
     "duration": 0.010589,
     "end_time": "2023-03-11T21:16:16.328876",
     "exception": false,
     "start_time": "2023-03-11T21:16:16.318287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"color:#fff; display:fill; border-width:1px; border-color:#000; font-size:125%;\">\n",
    "    <p style=\"border-style:solid; border-radius:8px; background-color:#fff; padding: 8px 12px 8px 12px; color:#000;\"><b>Multi-Head Attention</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ecde7a",
   "metadata": {
    "papermill": {
     "duration": 0.009248,
     "end_time": "2023-03-11T21:16:16.347895",
     "exception": false,
     "start_time": "2023-03-11T21:16:16.338647",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Multi-head attention was introduced in [Attention is all you need](https://arxiv.org/abs/1706.03762) and is wayyy to technical for me to try and explain here. But basically, it allows for multiple Scaled Dot-Production Attention functions to be run in parallel. 😅\n",
    "    \n",
    "[<img src=\"https://ar5iv.labs.arxiv.org/html/1706.03762/assets/Figures/ModalNet-20.png\" width=\"200\">](https://arxiv.org/abs/1706.03762)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1bb3ca80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-11T21:16:16.368012Z",
     "iopub.status.busy": "2023-03-11T21:16:16.367718Z",
     "iopub.status.idle": "2023-03-11T21:16:16.379572Z",
     "shell.execute_reply": "2023-03-11T21:16:16.378577Z"
    },
    "papermill": {
     "duration": 0.024366,
     "end_time": "2023-03-11T21:16:16.381708",
     "exception": false,
     "start_time": "2023-03-11T21:16:16.357342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, h, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.h = h\n",
    "        if embed_dim % h != 0:\n",
    "            raise ValueError(\n",
    "                f\"dimension of the embedding space = {embed_dim} should be divisible by number of heads = {h}\"\n",
    "            )\n",
    "        self.q_linear = tf.keras.layers.Dense(embed_dim)\n",
    "        self.k_linear = tf.keras.layers.Dense(embed_dim)\n",
    "        self.v_linear = tf.keras.layers.Dense(embed_dim)\n",
    "        self.concat_linear = tf.keras.layers.Dense(embed_dim)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, shape=(batch_size, -1, self.h, self.embed_dim // self.h))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def concat_heads(self, x, batch_size):\n",
    "        x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        return tf.reshape(x, (batch_size, -1, self.embed_dim))\n",
    "\n",
    "    def call(self, q, k, v, use_causal_mask=False):\n",
    "        batch_size = tf.shape(k)[0]\n",
    "        q = self.q_linear(q)\n",
    "        k = self.k_linear(k)\n",
    "        v = self.v_linear(v)\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "        attention = scaled_dot_product_attention(q, k, v, use_causal_mask)\n",
    "        concat = self.concat_heads(attention, batch_size)\n",
    "        concat = self.concat_linear(concat)\n",
    "        return concat\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(MultiHeadAttention, self).get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"h\": self.h,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef59d71",
   "metadata": {
    "papermill": {
     "duration": 0.009301,
     "end_time": "2023-03-11T21:16:16.400893",
     "exception": false,
     "start_time": "2023-03-11T21:16:16.391592",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"color:#000; display:fill; border-radius:8px; background-color:#000; font-size:125%;\">\n",
    "    <p style=\"padding: 8px 12px 8px 12px; color:#fff;\"><b>The Encoder</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdb658a",
   "metadata": {
    "papermill": {
     "duration": 0.009247,
     "end_time": "2023-03-11T21:16:16.419668",
     "exception": false,
     "start_time": "2023-03-11T21:16:16.410421",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "[<img src=\"https://raw.githubusercontent.com/nlp-with-transformers/notebooks/main/images/chapter03_encoder-zoom.png\" width=\"400\">](https://github.com/nlp-with-transformers/notebooks/blob/main/03_transformer-anatomy.ipynb)\n",
    "\n",
    "The role of the Encoder is to process the source sentence. Here, no Causal Masking is needed : information is allowed to flow in both directions (words can be aware of words before **and** after them in the sentence).\n",
    "\n",
    "The Encoder's a pretty generic module that ingests a sentence and learns to turn it into a more useful representation. It can also be used by itself (without the Decoder) for Natural Language Understanding (NLU) tasks like Classification or Named Entity Recognition (NER).\n",
    "\n",
    "In the Encoder's Multi-Head Self-Attention layer ([Global self-attention layer](https://www.tensorflow.org/text/tutorials/transformer#the_global_self_attention_layer)), the **Source Vectors Embeddings** are being passed to all three parameters : **Q**uery, **K**ey, and **V**alue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f513888",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-11T21:16:16.439695Z",
     "iopub.status.busy": "2023-03-11T21:16:16.439419Z",
     "iopub.status.idle": "2023-03-11T21:16:16.450488Z",
     "shell.execute_reply": "2023-03-11T21:16:16.449472Z"
    },
    "papermill": {
     "duration": 0.023479,
     "end_time": "2023-03-11T21:16:16.452570",
     "exception": false,
     "start_time": "2023-03-11T21:16:16.429091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerEncoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.layer_norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-7)\n",
    "        self.layer_norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-7)\n",
    "        self.global_self_attention = MultiHeadAttention(embed_dim=embed_dim, h=num_heads)\n",
    "        self.feed_forward = tf.keras.Sequential(\n",
    "            [tf.keras.layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             tf.keras.layers.Dense(embed_dim),]\n",
    "        )\n",
    "        \n",
    "    def call(self, x):\n",
    "        # Post layer normalization + residual connections\n",
    "        x = self.layer_norm_1(x + self.global_self_attention(q=x, k=x, v=x))\n",
    "        x = self.layer_norm_2(x + self.feed_forward(x))\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cac4a9a",
   "metadata": {
    "papermill": {
     "duration": 0.009332,
     "end_time": "2023-03-11T21:16:16.471316",
     "exception": false,
     "start_time": "2023-03-11T21:16:16.461984",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"color:#000; display:fill; border-radius:8px; background-color:#000; font-size:125%;\">\n",
    "    <p style=\"padding: 8px 12px 8px 12px; color:#fff;\"><b>The Decoder</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5334b0d1",
   "metadata": {
    "papermill": {
     "duration": 0.009386,
     "end_time": "2023-03-11T21:16:16.490286",
     "exception": false,
     "start_time": "2023-03-11T21:16:16.480900",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "[<img src=\"https://raw.githubusercontent.com/nlp-with-transformers/notebooks/main/images/chapter03_decoder-zoom.png\" width=\"500\">](https://github.com/nlp-with-transformers/notebooks/blob/main/03_transformer-anatomy.ipynb)\n",
    "\n",
    "The role of the Decoder is to look at the target sentence so far and predict the next word in that sentence.\n",
    "\n",
    "Contrary to the Encoder, the Decoder is made of two Attention layers. The first Attention layer does a similar job as the Encoder's sole Attention layer, with the important distinction that here, Causal Masking is enabled because, to correctly train our Transformer to predict the next word based on the current word and the previous words in the sentence, we need to mask the *after-words*. Meanwhile, The second Attention layer is much more straight-forward and basically just acts as a bridge that connects the Encoder to the Decoder.\n",
    "\n",
    "In the Decoder's first Attention layer, the Masked Multi-Head Self-Attention layer ([Causal self-attention layer](https://www.tensorflow.org/text/tutorials/transformer#the_causal_self_attention_layer)), the **Target Vectors Embeddings** are being passed to all three parameters : **Q**uery, **K**ey, and **V**alue. Like mentionned above, Causal Masking is enabled in this layer.\n",
    "\n",
    "In the Decoder's second Attention layer, the Encoder-Decoder Attention layer ([Cross attention layer](https://www.tensorflow.org/text/tutorials/transformer#the_cross_attention_layer)), the **outputs of the Encoder** are being passed to the **K**ey and **V**alue parameters, with the **outputs of the Decoder's Masked Multi-Head Self-Attention layer** being passed to the **Q**uery parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efd857c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-11T21:16:16.511448Z",
     "iopub.status.busy": "2023-03-11T21:16:16.510675Z",
     "iopub.status.idle": "2023-03-11T21:16:16.521790Z",
     "shell.execute_reply": "2023-03-11T21:16:16.520904Z"
    },
    "papermill": {
     "duration": 0.023884,
     "end_time": "2023-03-11T21:16:16.523763",
     "exception": false,
     "start_time": "2023-03-11T21:16:16.499879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerDecoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.causal_self_attention = MultiHeadAttention(embed_dim=embed_dim, h=num_heads)\n",
    "        self.cross_attention = MultiHeadAttention(embed_dim=embed_dim, h=num_heads)\n",
    "        self.feed_forward = tf.keras.Sequential(\n",
    "            [tf.keras.layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             tf.keras.layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layer_norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-7)\n",
    "        self.layer_norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-7)\n",
    "        self.layer_norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-7)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, x, context):\n",
    "        # Post layer normalization + residual connections\n",
    "        x = self.layer_norm_1(x + self.causal_self_attention(q=x, k=x, v=x, use_causal_mask=True))\n",
    "        x = self.layer_norm_2(x + self.cross_attention(q=x, k=context, v=context))\n",
    "        x = self.layer_norm_3(x + self.feed_forward(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f49afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(tf.keras.layers.Layer):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53315fb6",
   "metadata": {
    "papermill": {
     "duration": 0.009308,
     "end_time": "2023-03-11T21:16:16.542819",
     "exception": false,
     "start_time": "2023-03-11T21:16:16.533511",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"color:#000; display:fill; border-radius:8px; background-color:#000; font-size:125%;\">\n",
    "    <p style=\"padding: 8px 12px 8px 12px; color:#fff;\"><b>Putting it all together</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff7ddab",
   "metadata": {
    "papermill": {
     "duration": 0.009317,
     "end_time": "2023-03-11T21:16:16.561916",
     "exception": false,
     "start_time": "2023-03-11T21:16:16.552599",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "[<img src=\"https://ar5iv.labs.arxiv.org/html/1706.03762/assets/Figures/ModalNet-21.png\" width=\"300\">](https://arxiv.org/abs/1706.03762)\n",
    "\n",
    "We  turn our data into a *tf.data pipeline* that returns a tuple (Inputs, Outputs) where Inputs is a dict with two keys : **encoder_inputs** (the source sentence) and **decoder_inputs** (the target sentence), and Outputs is a single key : **decoder_outputs** (the target sentence \"shifted right\").\n",
    "\n",
    "During training, the fact that our Outputs are offset by one step ahead (\"shifted right\"), combined with the Causal Masking of the Decoder (Masked Multi-Head Attention layer), ensures that the\n",
    "predictions for position *i* can depend only on the known outputs at positions less than *i* (no *after-words* visible).\n",
    "\n",
    "During inference, we'll generate one target word at a time and then feed it back into the Decoder so that it can predict the next word. And so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3315e28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-11T21:16:16.582703Z",
     "iopub.status.busy": "2023-03-11T21:16:16.581946Z",
     "iopub.status.idle": "2023-03-11T21:16:16.837345Z",
     "shell.execute_reply": "2023-03-11T21:16:16.836348Z"
    },
    "papermill": {
     "duration": 0.268342,
     "end_time": "2023-03-11T21:16:16.839869",
     "exception": false,
     "start_time": "2023-03-11T21:16:16.571527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "def format_dataset(source, target):\n",
    "    source_vectors = source_vectorization(source)\n",
    "    target_vectors = target_vectorization(target)\n",
    "    return ({\n",
    "        \"source\": source_vectors, # encoder_inputs\n",
    "        \"target\": target_vectors[:, :-1], # decoder_inputs (truncate by 1 to keep it at the same length as decoder_outputs, which is shifted right by 1).\n",
    "    }, target_vectors[:, 1:]) # decoder_outputs\n",
    "\n",
    "def make_dataset(df):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((df[\"source\"].values, df[\"target\"].values))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
    "    return dataset.shuffle(2048).prefetch(16).cache()\n",
    "\n",
    "train_ds = make_dataset(train_df)\n",
    "val_ds = make_dataset(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77efcbff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-11T21:16:16.861407Z",
     "iopub.status.busy": "2023-03-11T21:16:16.860859Z",
     "iopub.status.idle": "2023-03-11T21:16:17.901338Z",
     "shell.execute_reply": "2023-03-11T21:16:17.900132Z"
    },
    "papermill": {
     "duration": 1.053699,
     "end_time": "2023-03-11T21:16:17.903679",
     "exception": false,
     "start_time": "2023-03-11T21:16:16.849980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Inputs: (32, 15)\n",
      "Decoder Inputs: (32, 15)\n",
      "Decoder Outputs: (32, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-23 23:45:55.514836: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# display the shape of the first batch of data in the dataset just to see what it looks like\n",
    "for batch in train_ds.take(1):\n",
    "    print(\"Encoder Inputs:\", batch[0][\"source\"].shape)\n",
    "    print(\"Decoder Inputs:\", batch[0][\"target\"].shape)\n",
    "    print(\"Decoder Outputs:\", batch[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be54cec",
   "metadata": {
    "papermill": {
     "duration": 0.009675,
     "end_time": "2023-03-11T21:16:17.923413",
     "exception": false,
     "start_time": "2023-03-11T21:16:17.913738",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "[<img src=\"https://raw.githubusercontent.com/nlp-with-transformers/notebooks/main/images/chapter03_transformer-encoder-decoder.png\" width=\"600\">](https://github.com/nlp-with-transformers/notebooks/blob/main/03_transformer-anatomy.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5808350e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class abc(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, num_layers):\n",
    "        super(bac, self).__init__()\n",
    "\n",
    "        self.transformer_encoders = [TransformerEncoder(embed_dim, dense_dim, num_heads) for _ in range(num_layers)]\n",
    "\n",
    "    def call(self, x):\n",
    "        for encoder in self.transformer_encoders:\n",
    "            x = encoder(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35f05fbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-11T21:16:17.945178Z",
     "iopub.status.busy": "2023-03-11T21:16:17.944831Z",
     "iopub.status.idle": "2023-03-11T21:16:19.583132Z",
     "shell.execute_reply": "2023-03-11T21:16:19.582129Z"
    },
    "papermill": {
     "duration": 1.653065,
     "end_time": "2023-03-11T21:16:19.586407",
     "exception": false,
     "start_time": "2023-03-11T21:16:17.933342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embed_dim = 64 # dimension of the embedding space\n",
    "dense_dim = 4*embed_dim # dimension of the feed forward network (a rule of thumb is to use 4 times the size of the embeddings)\n",
    "num_heads = 4\n",
    "\n",
    "# the transformer body\n",
    "encoder_inputs = tf.keras.Input(shape=(None,), dtype=\"int64\", name=\"source\")\n",
    "x = PositionalEmbedding(sequence_length, max_tokens, embed_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder2(embed_dim, dense_dim, num_heads, 2)(x)\n",
    "decoder_inputs = tf.keras.Input(shape=(None,), dtype=\"int64\", name=\"target\")\n",
    "x = PositionalEmbedding(sequence_length, max_tokens, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
    "\n",
    "# the transformer head\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "decoder_outputs = tf.keras.layers.Dense(max_tokens, activation=\"softmax\")(x)\n",
    "\n",
    "transformer = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa4b744",
   "metadata": {
    "papermill": {
     "duration": 0.014633,
     "end_time": "2023-03-11T21:16:19.617500",
     "exception": false,
     "start_time": "2023-03-11T21:16:19.602867",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training the Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e059938e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-11T21:16:19.648313Z",
     "iopub.status.busy": "2023-03-11T21:16:19.647850Z",
     "iopub.status.idle": "2023-03-11T22:49:33.526355Z",
     "shell.execute_reply": "2023-03-11T22:49:33.525131Z"
    },
    "papermill": {
     "duration": 5596.689391,
     "end_time": "2023-03-11T22:49:36.321627",
     "exception": false,
     "start_time": "2023-03-11T21:16:19.632236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-23 23:53:34.804309: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f17b000df40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-23 23:53:34.804350: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3080 Laptop GPU, Compute Capability 8.6\n",
      "2024-01-23 23:53:34.810268: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-01-23 23:53:35.150187: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1706050415.205284  132548 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  55/2188 [..............................] - ETA: 4:10 - loss: 8.0243 - accuracy: 0.1199"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 27\u001b[0m\n\u001b[1;32m      7\u001b[0m checkpoint_filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/tmp/checkpoint/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      8\u001b[0m callbacks_list \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(\n\u001b[1;32m     10\u001b[0m         monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     ),\n\u001b[1;32m     25\u001b[0m ]\n\u001b[0;32m---> 27\u001b[0m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# transformer.load_weights(checkpoint_filepath)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/transformer/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/transformer/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/transformer/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/transformer/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/transformer/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/transformer/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/transformer/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/transformer/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/transformer/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/transformer/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/transformer/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "transformer.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "EPOCHS = 1\n",
    "checkpoint_filepath = '/tmp/checkpoint/'\n",
    "callbacks_list = [\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.1,\n",
    "        patience=3,\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=6,\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_best_only=True\n",
    "    ),\n",
    "]\n",
    "    \n",
    "transformer.fit(train_ds, \n",
    "                epochs=EPOCHS, \n",
    "                callbacks=callbacks_list,\n",
    "                validation_data=val_ds)\n",
    "\n",
    "# transformer.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6ae7fd",
   "metadata": {
    "papermill": {
     "duration": 2.824481,
     "end_time": "2023-03-11T22:49:42.234058",
     "exception": false,
     "start_time": "2023-03-11T22:49:39.409577",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Testing the Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f3e482",
   "metadata": {
    "papermill": {
     "duration": 3.027052,
     "end_time": "2023-03-11T22:49:48.197292",
     "exception": false,
     "start_time": "2023-03-11T22:49:45.170240",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's translate a few random test sentences with our newly-trained Transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e7a4264",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-11T22:49:53.787024Z",
     "iopub.status.busy": "2023-03-11T22:49:53.786670Z",
     "iopub.status.idle": "2023-03-11T22:50:13.522173Z",
     "shell.execute_reply": "2023-03-11T22:50:13.520854Z"
    },
    "papermill": {
     "duration": 22.5185,
     "end_time": "2023-03-11T22:50:13.524481",
     "exception": false,
     "start_time": "2023-03-11T22:49:51.005981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'target_vectorization' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m target_vocab \u001b[38;5;241m=\u001b[39m \u001b[43mtarget_vectorization\u001b[49m\u001b[38;5;241m.\u001b[39mget_vocabulary()\n\u001b[1;32m      2\u001b[0m target_index_lookup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(target_vocab)), target_vocab))\n\u001b[1;32m      3\u001b[0m max_decoded_sentence_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'target_vectorization' is not defined"
     ]
    }
   ],
   "source": [
    "target_vocab = target_vectorization.get_vocabulary()\n",
    "target_index_lookup = dict(zip(range(len(target_vocab)), target_vocab))\n",
    "max_decoded_sentence_length = 10\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = target_vectorization(\n",
    "            [decoded_sentence])[:, :-1]\n",
    "        predictions = transformer(\n",
    "            [tokenized_input_sentence, tokenized_target_sentence])\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = target_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence\n",
    "\n",
    "# let's translate 50 random sentences\n",
    "for i in range(50):\n",
    "    random_index = np.random.randint(0, len(test_df))\n",
    "    input_sentence = test_df[\"source\"].iloc[random_index]\n",
    "    print(input_sentence)\n",
    "    print(decode_sequence(input_sentence))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9e1689",
   "metadata": {
    "papermill": {
     "duration": 2.956276,
     "end_time": "2023-03-11T22:50:19.334117",
     "exception": false,
     "start_time": "2023-03-11T22:50:16.377841",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Credits and stuff\n",
    "\n",
    "- https://arxiv.org/abs/1706.03762\n",
    "\n",
    "- https://www.tensorflow.org/text/tutorials/transformer\n",
    "\n",
    "- https://github.com/openai/gpt-2/blob/master/src/model.py\n",
    "\n",
    "- https://github.com/karpathy/minGPT/blob/master/mingpt/model.py\n",
    "\n",
    "- https://livebook.manning.com/book/deep-learning-with-python-second-edition/chapter-11\n",
    "\n",
    "    - https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/chapter11_part03_transformer.ipynb\n",
    "\n",
    "    - https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/chapter11_part04_sequence-to-sequence-learning.ipynb\n",
    "\n",
    "- https://www.oreilly.com/library/view/natural-language-processing/9781098136789/ch03.html\n",
    "\n",
    "    - https://github.com/nlp-with-transformers/notebooks/blob/main/03_transformer-anatomy.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5693.346436,
   "end_time": "2023-03-11T22:50:26.592976",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-11T21:15:33.246540",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
